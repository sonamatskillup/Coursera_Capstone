{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Applied Data Science Capstone Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "> Data Science Report on Car Accident Severity"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "## Data Understanding\n\nThis section contains a description of the data and how it will be used to solve the problem. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The dataset of size about 1,90,000 found in the file `Data-Collisions.csv` includes all types of collisions at Seattle from 2004 to present that are updated weekly. The data contains comma separated values having 37 attributes with the following highlighted attributes:\n\n1. Text `ADDRTYPE` of length 12 describing collision address types.\n    - Alley\n    - Block\n    - Intersection\n2. Text `SEVERITYCODE` of length 100 that codes the severity of collision.\n    - 3\n    - 2b\n    - 2\n    - 1\n    - 0\n3. Text `WEATHER` of length 300 describing weather conditions during the collision.\n4. Text `ROADCOND` of length 300 denoting road conditions during the collision.\n5. Text `LIGHTCOND` of length 300 with details of light conditions during the collision.\n\nThe data in the csv file is not fit for analysis as there are multiple columns where the features do not have numerical type. Hence, label encoding is required for conversion to the desired data type.\n\nWe shall be using the following attributes for our analysis:\n\n| Attribute       | Data Type   |\n|-----------------|-------------|\n| `SEVERITYCODE`  | `int64`     |\n| `WEATHER`       | `category`  |\n| `ROADCOND`      | `category`  |\n| `LIGHTCOND`     | `category`  |\n| `WEATHER_CAT`   | `int8`      |\n| `ROADCOND_CAT`  | `int8`      |\n| `LIGHTCOND_CAT` | `int8`      |\n\nThe data analysis begins with normalizing the dataset and splitting it in a 70% training and 30% testing. Next, the modeling and predictions are operated on the models as below:\n\n1. k-Nearest Neighbours\n\n2. Decision Tree\n\n3. Logistic Regression\n\nFinally, the evaluation metrics are being used for accuracy testing of our models were jaccard index, f-1 score and logloss"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}